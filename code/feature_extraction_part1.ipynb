{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27144\\168248541.py:16: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[var_name] = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the rawData folder\n",
    "raw_data_folder = '../data/rawData'\n",
    "\n",
    "# Get all .csv files in that folder\n",
    "csv_files = [f for f in os.listdir(raw_data_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Loop through all CSV files, read them into pandas DataFrames, and use the file name (without extension) as the variable name\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(raw_data_folder, file)\n",
    "    # Remove the file extension to use as the variable name\n",
    "    var_name = os.path.splitext(file)[0]\n",
    "    # Use globals() to assign each DataFrame directly as a global variable\n",
    "    globals()[var_name] = pd.read_csv(file_path)\n",
    "\n",
    "# Load the processed patient label CSV file\n",
    "patient_labeled = pd.read_csv(r'../data/processedData/patient_label.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuer Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Feature Selection and Merging of Patient Data (from patient_labs, patient_information, EPIC_MRN_PAT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             LOG_ID            PAT_ID               MRN  Cardiovascular   LOS  \\\n",
      "0  d754f06a7d973a26  837532f458d9c660  0b8de903ea63082a             0.0   1.0   \n",
      "1  5a95970d5c8fc355  fd18a41f136ed278  0a8b72c1cec4ae47             0.0  10.0   \n",
      "2  138d44a06cf4b57f  fd18a41f136ed278  0a8b72c1cec4ae47             0.0  10.0   \n",
      "3  82372dc4703ea1b0  648781c95d863ec6  e0cb9244fedd1ac7             0.0   3.0   \n",
      "4  4b6aabaf62e85c0a  d1d7b9ddc4962cdf  3918b79e03cefe27             0.0   3.0   \n",
      "\n",
      "  ICU_ADMIN_FLAG HEIGHT   WEIGHT     SEX  ASA_RATING_C Abnormal Flag  \n",
      "0             No   6' 2  3089.97    Male           2.0           NaN  \n",
      "1            Yes    NaN  3365.10    Male           3.0           NaN  \n",
      "2            Yes    NaN  3365.10    Male           3.0           NaN  \n",
      "3            Yes   5' 3  2336.88  Female           2.0           NaN  \n",
      "4            Yes    NaN  2879.74    Male           2.0             N  \n",
      "(1604, 11)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates based on 'LOG_ID' from the EPIC_MRN_PAT_ID and patient_labeled DataFrame\n",
    "epic_data_selected = EPIC_MRN_PAT_ID.drop_duplicates(subset=['LOG_ID'])\n",
    "label_data_selected = patient_labeled.drop_duplicates(subset=['LOG_ID'])\n",
    "\n",
    "# Merge the EPIC data and patient labels on 'LOG_ID' and 'MRN'\n",
    "merged_1 = pd.merge(epic_data_selected, label_data_selected, on=['LOG_ID', 'MRN'], how='inner')\n",
    "\n",
    "# Select relevant columns from patient_information and remove duplicates based on 'LOG_ID',\n",
    "# then merge with the previous DataFrame (merged_1) using an inner join\n",
    "df_patient_information_features = patient_information[['LOG_ID', 'LOS', 'ICU_ADMIN_FLAG', 'HEIGHT', 'WEIGHT', 'SEX', 'ASA_RATING_C']]\n",
    "df_patient_information_selected = df_patient_information_features.drop_duplicates(subset=['LOG_ID'])\n",
    "merged_2 = pd.merge(merged_1, df_patient_information_selected, on=['LOG_ID'], how='inner')\n",
    "\n",
    "# Remove duplicates from patient_labs based on 'LOG_ID', select relevant columns, \n",
    "# and left join with the previously merged DataFrame (merged_2) on 'LOG_ID'\n",
    "df_patient_labs_selected = patient_labs.drop_duplicates(subset=['LOG_ID'])\n",
    "df_patient_labs_features = df_patient_labs_selected[['LOG_ID', 'Abnormal Flag']]\n",
    "merged_3 = pd.merge(merged_2, df_patient_labs_features, on=['LOG_ID'], how='left')\n",
    "\n",
    "# Print the first few rows of the final merged DataFrame\n",
    "print(merged_3.head())\n",
    "print(merged_3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Feature Selection and Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.25145853658537\n",
      "                LOG_ID            PAT_ID               MRN  Cardiovascular  \\\n",
      "0     d754f06a7d973a26  837532f458d9c660  0b8de903ea63082a             0.0   \n",
      "1     5a95970d5c8fc355  fd18a41f136ed278  0a8b72c1cec4ae47             0.0   \n",
      "2     138d44a06cf4b57f  fd18a41f136ed278  0a8b72c1cec4ae47             0.0   \n",
      "3     82372dc4703ea1b0  648781c95d863ec6  e0cb9244fedd1ac7             0.0   \n",
      "4     4b6aabaf62e85c0a  d1d7b9ddc4962cdf  3918b79e03cefe27             0.0   \n",
      "...                ...               ...               ...             ...   \n",
      "1599  8116aa4a100ceee8  478a3cd8857cc055  72accda5075f7a39             1.0   \n",
      "1600  3c146c502e1e249d  fa6ec9ad3f5f1466  2408210232a3e06b             0.0   \n",
      "1601  cecd35a626c55d0c  b9878cd048a80cb3  5b9cf2e5349171e8             1.0   \n",
      "1602  3333ade5695c0b55  2f091eb1b00105d4  c280ccc5e979b4ef             0.0   \n",
      "1603  c34b85c0cf941d8a  b5838d1cdf37c09c  d7946ede59551209             1.0   \n",
      "\n",
      "       LOS  ICU_ADMIN_FLAG      HEIGHT   WEIGHT  SEX  ASA_RATING_C  \\\n",
      "0      1.0               0  187.960000  3089.97    1           2.0   \n",
      "1     10.0               1  168.251459  3365.10    1           3.0   \n",
      "2     10.0               1  168.251459  3365.10    1           3.0   \n",
      "3      3.0               1  160.020000  2336.88    0           2.0   \n",
      "4      3.0               1  168.251459  2879.74    1           2.0   \n",
      "...    ...             ...         ...      ...  ...           ...   \n",
      "1599  34.0               1  165.100000  2405.66    1           3.0   \n",
      "1600   1.0               0  154.940000  2338.64    0           3.0   \n",
      "1601  77.0               1  166.370000  1742.52    0           3.0   \n",
      "1602   7.0               1  162.560000  2380.97    0           3.0   \n",
      "1603   7.0               1  154.940000  1516.76    0           3.0   \n",
      "\n",
      "      Abnormal Flag  \n",
      "0          0.355511  \n",
      "1          0.355511  \n",
      "2          0.355511  \n",
      "3          0.355511  \n",
      "4          0.000000  \n",
      "...             ...  \n",
      "1599       0.000000  \n",
      "1600       2.000000  \n",
      "1601       0.000000  \n",
      "1602       0.000000  \n",
      "1603       1.000000  \n",
      "\n",
      "[1604 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27144\\3780084398.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_3['HEIGHT'].fillna(mean_height, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27144\\3780084398.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_3['ICU_ADMIN_FLAG'] = merged_3['ICU_ADMIN_FLAG'].replace({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27144\\3780084398.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_3['SEX'] = merged_3['SEX'].replace({\"Female\": 0, \"Male\": 1})\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27144\\3780084398.py:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_3['Abnormal Flag'] = merged_3['Abnormal Flag'].replace(abnormal_flag_mapping)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27144\\3780084398.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_3['Abnormal Flag'].fillna(mean_abnormal_flag, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Function to convert height from feet and inches format to centimeters\n",
    "def height_to_inches(height):\n",
    "    if pd.isna(height):\n",
    "        return np.nan\n",
    "    feet, inches = height.split(\"' \")\n",
    "    return (int(feet) * 12 + float(inches)) * 2.54\n",
    "\n",
    "# Apply the height_to_inches function to the 'HEIGHT' column to convert height to centimeters\n",
    "merged_3['HEIGHT'] = merged_3['HEIGHT'].apply(height_to_inches)\n",
    "\n",
    "# Calculate the mean height (in centimeters) after conversion\n",
    "mean_height = merged_3['HEIGHT'].mean()\n",
    "print(mean_height)\n",
    "\n",
    "# Fill missing values (NaNs) in the 'HEIGHT' column with the calculated mean height\n",
    "merged_3['HEIGHT'].fillna(mean_height, inplace=True)\n",
    "\n",
    "# Convert 'ICU_ADMIN_FLAG' from 'Yes'/'No' to binary 1/0\n",
    "merged_3['ICU_ADMIN_FLAG'] = merged_3['ICU_ADMIN_FLAG'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Convert 'SEX' from 'Female'/'Male' to binary 0/1\n",
    "merged_3['SEX'] = merged_3['SEX'].replace({\"Female\": 0, \"Male\": 1})\n",
    "\n",
    "# Create a mapping for the 'Abnormal Flag' column\n",
    "abnormal_flag_mapping = {\n",
    "    'N': 0,   # Normal\n",
    "    'L': 1,   # Low\n",
    "    'H': 2,   # High\n",
    "    'LL': 3,  # Very Low\n",
    "    'HH': 4   # Very High\n",
    "}\n",
    "\n",
    "# Replace values in 'Abnormal Flag' column using the defined mapping\n",
    "merged_3['Abnormal Flag'] = merged_3['Abnormal Flag'].replace(abnormal_flag_mapping)\n",
    "\n",
    "# Calculate the mean of the 'Abnormal Flag' column\n",
    "mean_abnormal_flag = merged_3['Abnormal Flag'].mean()\n",
    "\n",
    "# Fill missing values (NaNs) in 'Abnormal Flag' with the calculated mean\n",
    "merged_3['Abnormal Flag'].fillna(mean_abnormal_flag, inplace=True)\n",
    "\n",
    "# Select relevant columns from 'merged_3' as features and fill missing values \n",
    "# in numerical columns (both in 'feature_1' and 'merged_3') with their column mean\n",
    "feature_1 = merged_3[['Cardiovascular','LOS','ICU_ADMIN_FLAG','ICU_ADMIN_FLAG','HEIGHT','SEX','ASA_RATING_C','Abnormal Flag']]\n",
    "feature_1 = feature_1.apply(lambda x: x.fillna(x.mean()) if x.dtype.kind in 'biufc' else x)\n",
    "merged_4 = merged_3.apply(lambda x: x.fillna(x.mean()) if x.dtype.kind in 'biufc' else x)\n",
    "\n",
    "# Print the final DataFrame after filling missing values\n",
    "print(merged_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Processing(from patient_medications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                LOG_ID            PAT_ID               MRN  Cardiovascular  \\\n",
      "0     d754f06a7d973a26  837532f458d9c660  0b8de903ea63082a             0.0   \n",
      "1     5a95970d5c8fc355  fd18a41f136ed278  0a8b72c1cec4ae47             0.0   \n",
      "2     138d44a06cf4b57f  fd18a41f136ed278  0a8b72c1cec4ae47             0.0   \n",
      "3     82372dc4703ea1b0  648781c95d863ec6  e0cb9244fedd1ac7             0.0   \n",
      "4     4b6aabaf62e85c0a  d1d7b9ddc4962cdf  3918b79e03cefe27             0.0   \n",
      "...                ...               ...               ...             ...   \n",
      "1599  8116aa4a100ceee8  478a3cd8857cc055  72accda5075f7a39             1.0   \n",
      "1600  3c146c502e1e249d  fa6ec9ad3f5f1466  2408210232a3e06b             0.0   \n",
      "1601  cecd35a626c55d0c  b9878cd048a80cb3  5b9cf2e5349171e8             1.0   \n",
      "1602  3333ade5695c0b55  2f091eb1b00105d4  c280ccc5e979b4ef             0.0   \n",
      "1603  c34b85c0cf941d8a  b5838d1cdf37c09c  d7946ede59551209             1.0   \n",
      "\n",
      "       LOS  ICU_ADMIN_FLAG      HEIGHT   WEIGHT  SEX  ASA_RATING_C  \\\n",
      "0      1.0               0  187.960000  3089.97    1           2.0   \n",
      "1     10.0               1  168.251459  3365.10    1           3.0   \n",
      "2     10.0               1  168.251459  3365.10    1           3.0   \n",
      "3      3.0               1  160.020000  2336.88    0           2.0   \n",
      "4      3.0               1  168.251459  2879.74    1           2.0   \n",
      "...    ...             ...         ...      ...  ...           ...   \n",
      "1599  34.0               1  165.100000  2405.66    1           3.0   \n",
      "1600   1.0               0  154.940000  2338.64    0           3.0   \n",
      "1601  77.0               1  166.370000  1742.52    0           3.0   \n",
      "1602   7.0               1  162.560000  2380.97    0           3.0   \n",
      "1603   7.0               1  154.940000  1516.76    0           3.0   \n",
      "\n",
      "      Abnormal Flag  ORDER_STATUS_IMPACT  \n",
      "0          0.355511                  1.0  \n",
      "1          0.355511                  1.0  \n",
      "2          0.355511                  1.0  \n",
      "3          0.355511                  1.0  \n",
      "4          0.000000                  2.0  \n",
      "...             ...                  ...  \n",
      "1599       0.000000                  0.0  \n",
      "1600       2.000000                  1.0  \n",
      "1601       0.000000                  0.0  \n",
      "1602       0.000000                  0.0  \n",
      "1603       1.000000                  0.0  \n",
      "\n",
      "[1604 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping for 'ORDER_STATUS_NM' values to numerical impacts\n",
    "order_status_mapping = {\n",
    "    'Verified': 2,         # High impact\n",
    "    'Completed': 2,        # High impact\n",
    "    'Dispensed': 1,        # Medium impact\n",
    "    'Sent': 1,             # Medium impact\n",
    "    'Discontinued': 0,     # No impact (discontinued)\n",
    "    'Canceled': 0,         # No impact (canceled)\n",
    "    '0 Discontinued': 0,   # No impact (alternative spelling)\n",
    "    '0 Dispensed': 0,      # No impact (alternative spelling)\n",
    "    'Unknown': 1           # Default impact for unknown status\n",
    "}\n",
    "\n",
    "# Fill missing values in 'ORDER_STATUS_NM' column with 'Unknown'\n",
    "patient_medications['ORDER_STATUS_NM'] = patient_medications['ORDER_STATUS_NM'].fillna('Unknown')\n",
    "\n",
    "# Map 'ORDER_STATUS_NM' to numerical values using 'order_status_mapping'\n",
    "patient_medications['ORDER_STATUS_IMPACT'] = patient_medications['ORDER_STATUS_NM'].map(order_status_mapping)\n",
    "\n",
    "# Select 'LOG_ID' and 'ORDER_STATUS_IMPACT', remove duplicates based on 'LOG_ID', \n",
    "# and left join with the previous DataFrame (merged_4)\n",
    "patient_osi = patient_medications[['LOG_ID', 'ORDER_STATUS_IMPACT']]\n",
    "patient_osi_unique = patient_osi.drop_duplicates(subset='LOG_ID')\n",
    "merged_5 = pd.merge(merged_4, patient_osi_unique, on='LOG_ID', how='left')\n",
    "\n",
    "# Fill missing values in 'ORDER_STATUS_IMPACT' with the default value of 1 (medium impact)\n",
    "merged_5['ORDER_STATUS_IMPACT'] = merged_5['ORDER_STATUS_IMPACT'].fillna(1)\n",
    "\n",
    "print(merged_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Processing (from patient_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                LOG_ID            PAT_ID               MRN  Cardiovascular  \\\n",
      "0     d754f06a7d973a26  837532f458d9c660  0b8de903ea63082a             0.0   \n",
      "1     5a95970d5c8fc355  fd18a41f136ed278  0a8b72c1cec4ae47             0.0   \n",
      "2     138d44a06cf4b57f  fd18a41f136ed278  0a8b72c1cec4ae47             0.0   \n",
      "3     82372dc4703ea1b0  648781c95d863ec6  e0cb9244fedd1ac7             0.0   \n",
      "4     4b6aabaf62e85c0a  d1d7b9ddc4962cdf  3918b79e03cefe27             0.0   \n",
      "...                ...               ...               ...             ...   \n",
      "1599  8116aa4a100ceee8  478a3cd8857cc055  72accda5075f7a39             1.0   \n",
      "1600  3c146c502e1e249d  fa6ec9ad3f5f1466  2408210232a3e06b             0.0   \n",
      "1601  cecd35a626c55d0c  b9878cd048a80cb3  5b9cf2e5349171e8             1.0   \n",
      "1602  3333ade5695c0b55  2f091eb1b00105d4  c280ccc5e979b4ef             0.0   \n",
      "1603  c34b85c0cf941d8a  b5838d1cdf37c09c  d7946ede59551209             1.0   \n",
      "\n",
      "       LOS  ICU_ADMIN_FLAG      HEIGHT    WEIGHT  SEX  ASA_RATING_C  \\\n",
      "0      1.0               0  187.960000   92.6991    1           2.0   \n",
      "1     10.0               1  168.251459  100.9530    1           3.0   \n",
      "2     10.0               1  168.251459  100.9530    1           3.0   \n",
      "3      3.0               1  160.020000   70.1064    0           2.0   \n",
      "4      3.0               1  168.251459   86.3922    1           2.0   \n",
      "...    ...             ...         ...       ...  ...           ...   \n",
      "1599  34.0               1  165.100000   72.1698    1           3.0   \n",
      "1600   1.0               0  154.940000   70.1592    0           3.0   \n",
      "1601  77.0               1  166.370000   52.2756    0           3.0   \n",
      "1602   7.0               1  162.560000   71.4291    0           3.0   \n",
      "1603   7.0               1  154.940000   45.5028    0           3.0   \n",
      "\n",
      "      Abnormal Flag  ORDER_STATUS_IMPACT  discharge_risk_level  BIRTH_DATE  \\\n",
      "0          0.355511                  1.0                     1          67   \n",
      "1          0.355511                  1.0                     1          57   \n",
      "2          0.355511                  1.0                     1          57   \n",
      "3          0.355511                  1.0                     1          69   \n",
      "4          0.000000                  2.0                     3          50   \n",
      "...             ...                  ...                   ...         ...   \n",
      "1599       0.000000                  0.0                     1          69   \n",
      "1600       2.000000                  1.0                     1          78   \n",
      "1601       0.000000                  0.0                     1          61   \n",
      "1602       0.000000                  0.0                     1          54   \n",
      "1603       1.000000                  0.0                     2          61   \n",
      "\n",
      "      PATIENT_CLASS_GROUP  PATIENT_CLASS_NM  \n",
      "0                       1                 2  \n",
      "1                       0                 1  \n",
      "2                       0                 0  \n",
      "3                       0                 1  \n",
      "4                       0                 1  \n",
      "...                   ...               ...  \n",
      "1599                    1                 2  \n",
      "1600                    1                 2  \n",
      "1601                    0                 0  \n",
      "1602                    0                 0  \n",
      "1603                    0                 0  \n",
      "\n",
      "[1604 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping for 'DISCH_DISP_C' to corresponding risk levels\n",
    "risk_levels = {\n",
    "    15.0: 1,  # Home Routine\n",
    "    106.0: 1,  # Independent Living\n",
    "    104.0: 1,  # Room and Board\n",
    "    20.0: 2,  # Home Healthcare IP Admit Related\n",
    "    21.0: 2,  # Home Healthcare Outside 3 Days\n",
    "    86.0: 2,  # Home Health w Planned Readmit\n",
    "    109.0: 2,  # Home Healthcare Outpatient Related\n",
    "    108.0: 2,  # Temporary Living\n",
    "    100.0: 3,  # Rehab Facility (this hospital)\n",
    "    4.0: 3,  # Rehab Facility (not this hospital)\n",
    "    6.0: 3,  # Skilled Nursing Facility\n",
    "    83.0: 3,  # Skilled Nursing w Planned Readmit\n",
    "    5.0: 3,  # Intermediate/Residential Care Facility\n",
    "    84.0: 3,  # Intermediate/Residential Care w Planned Readmit\n",
    "    107.0: 3,  # Sub-Acute Care Facility\n",
    "    103.0: 3,  # Board and Care\n",
    "    105.0: 3,  # Recuperative Care\n",
    "    8.0: 4,  # Acute Care Facility (this hospital)\n",
    "    26.0: 4,  # Acute Care Facility (not this hospital)\n",
    "    30.0: 4,  # Long Term Care Facility\n",
    "    19.0: 4,  # Psychiatric Facility (this hospital)\n",
    "    9.0: 4,  # Psychiatric Facility (not this hospital)\n",
    "    66.0: 4,  # Critical Access Hospital\n",
    "    18.0: 4,  # Cancer Ctr/Children's Hospital\n",
    "    102.0: 4,  # Shelter\n",
    "    69.0: 4,  # Designated Disaster Alternate Care Site\n",
    "    70.0: 4,  # Other Healthcare Not Defined in this List\n",
    "    11.0: 4,  # Federal Hospital\n",
    "    88.0: 4,  # Federal Hospital w Planned Readmit\n",
    "    16.0: 5,  # Hospice Facility\n",
    "    22.0: 5,  # Hospice Home\n",
    "    3.0: 5,  # Expired\n",
    "    23.0: 5,  # Coroner\n",
    "    13.0: 5,  # Against Medical Advice\n",
    "    10.0: 5,  # Jail/Prison\n",
    "    float('nan'): 0  # Unknown\n",
    "}\n",
    "\n",
    "# Map 'DISCH_DISP_C' column to 'discharge_risk_level' using risk_levels mapping and fill missing values with 0\n",
    "patient_information['discharge_risk_level'] = patient_information['DISCH_DISP_C'].map(risk_levels).fillna(0)\n",
    "\n",
    "# Select 'LOG_ID', 'discharge_risk_level', and 'BIRTH_DATE' columns, remove duplicates based on 'LOG_ID',\n",
    "# and merge with the previous DataFrame (merged_5) using a left join on 'LOG_ID'\n",
    "patient_information_selected = patient_information[['LOG_ID', 'discharge_risk_level', 'BIRTH_DATE']]\n",
    "patient_information_unique = patient_information_selected.drop_duplicates(subset='LOG_ID')\n",
    "merged_6 = pd.merge(merged_5, patient_information_unique, on='LOG_ID', how='left')\n",
    "\n",
    "# Fill missing values in 'discharge_risk_level' and 'BIRTH_DATE' with their respective column means\n",
    "merged_6['discharge_risk_level'] = merged_6['discharge_risk_level'].fillna(merged_6['discharge_risk_level'].mean())\n",
    "merged_6['BIRTH_DATE'] = merged_6['BIRTH_DATE'].fillna(merged_6['BIRTH_DATE'].mean())\n",
    "\n",
    "pi_copy = patient_information.copy()\n",
    "# Map 'PATIENT_CLASS_GROUP' column to binary values (Outpatient = 1, Inpatient = 0)\n",
    "pi_copy['PATIENT_CLASS_GROUP'] = pi_copy['PATIENT_CLASS_GROUP'].map({'Outpatient': 1, 'Inpatient': 0})\n",
    "\n",
    "# Map 'PATIENT_CLASS_NM' column to numerical values for different patient class categories\n",
    "pi_copy['PATIENT_CLASS_NM'] = pi_copy['PATIENT_CLASS_NM'].map({'Hospital Outpatient Surgery': 2, 'Hospital Inpatient Surgery': 1, 'Inpatient Admission': 0})\n",
    "\n",
    "# Select 'LOG_ID', 'PATIENT_CLASS_GROUP', and 'PATIENT_CLASS_NM' columns for further processing\n",
    "feature_pi = pi_copy[['LOG_ID', 'PATIENT_CLASS_GROUP', 'PATIENT_CLASS_NM']]\n",
    "\n",
    "# Remove duplicates based on 'LOG_ID' to ensure unique entries\n",
    "patient_information_copy_unique = feature_pi.drop_duplicates(subset='LOG_ID')\n",
    "\n",
    "# Merge with the previous DataFrame (merged_6) based on 'LOG_ID'\n",
    "merged_7 = pd.merge(merged_6, patient_information_copy_unique, on='LOG_ID', how='left')\n",
    "\n",
    "# Fill missing values in 'PATIENT_CLASS_GROUP' and 'PATIENT_CLASS_NM' with their respective column means\n",
    "merged_7['PATIENT_CLASS_GROUP'] = merged_7['PATIENT_CLASS_GROUP'].fillna(merged_7['PATIENT_CLASS_GROUP'].mean())\n",
    "merged_7['PATIENT_CLASS_NM'] = merged_7['PATIENT_CLASS_NM'].fillna(merged_7['PATIENT_CLASS_NM'].mean())\n",
    "\n",
    "# Adjust 'WEIGHT' column by scaling down the values\n",
    "merged_7['WEIGHT'] = merged_7['WEIGHT'] / 100 * 3\n",
    "\n",
    "# Print the final merged DataFrame\n",
    "print(merged_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file in the processedData folder\n",
    "output_path = '../data/processedData/features_part1.csv'\n",
    "merged_7.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp90051_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
